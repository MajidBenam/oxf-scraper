{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appreciated-hudson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "personal-fellowship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going for word:  cushion 1\n",
      "[<span class=\"def\" hclass=\"def\" htag=\"span\">a cloth bag filled with soft material or feathers that is used, for example, to make a seat more comfortable</span>]\n",
      "[<span class=\"def\" hclass=\"def\" htag=\"span\">a layer of something between two surfaces that keeps them apart</span>]\n",
      "[<span class=\"def\" hclass=\"def\" htag=\"span\">something that protects you against something unpleasant that might happen</span>]\n",
      "[<span class=\"def\" hclass=\"def\" htag=\"span\">the soft inside edge along each side of the table that the balls <a class=\"Ref\" href=\"https://www.oxfordlearnersdictionaries.com/definition/english/bounce_1\" title=\"bounce definition\"><span class=\"ndv\">bounce</span></a> off</span>]\n",
      "Going for word:  cushion 2\n",
      "[<span class=\"def\" hclass=\"def\" htag=\"span\">to make the effect of a fall or hit less severe</span>]\n",
      "[<span class=\"def\" hclass=\"def\" htag=\"span\">to protect somebody/something from being hurt or damaged or from the unpleasant effects of something</span>]\n",
      "Going for word:  cushion 3\n"
     ]
    }
   ],
   "source": [
    "my_sngs = sng_situation_clearer(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in my_sngs:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dic = test_func(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(my_dic[\"wise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-london",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-ancient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"maroon\"\n",
    "word_dic = {}\n",
    "entry_dic = {}\n",
    "for index, item in enumerate(my_main_defs):\n",
    "    inner_dic = {}\n",
    "    for i in range(len(item)):\n",
    "        a_def = item[i].text\n",
    "        good_key_for_def = \"DEF_\" + str(i+1)\n",
    "        inner_dic[good_key_for_def] = a_def\n",
    "        print(a_def)\n",
    "    entry_dic[index] = inner_dic\n",
    "word_dic[word] = entry_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-newspaper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-dylan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-carbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-generic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-tension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-procedure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "\n",
    "\n",
    "source_url = 'https://www.oxfordlearnersdictionaries.com/definition/english/'\n",
    "\n",
    "# cool trick\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "\n",
    "my_list = [\"cushion\", \"trivial\", \"wanderer\"]\n",
    "my_words_dic = {}\n",
    "#source = requests.get(source_url, headers=headers).text\n",
    "for word in my_list:\n",
    "    my_dic = {}\n",
    "    try:\n",
    "        my_word_url = source_url + word\n",
    "        source = requests.get(my_word_url, headers=headers)\n",
    "        soup = BeautifulSoup(source.content.decode('utf-8'), 'lxml')\n",
    "        main_defs = soup.find_all('span', class_ = 'def')\n",
    "    except:\n",
    "        print(\"Bad Word...\")\n",
    "        \n",
    "    my_li = soup.find(id=\"cushion_sng_1\")\n",
    "    # selects the main text\n",
    "\n",
    "    main_examples = soup.find_all('span', class_ = 'x')\n",
    "    potential_image_links = soup.find_all('a', href=True)\n",
    "    #potential_image_links = soup.find_all('img')\n",
    "\n",
    "    # https://www.oxfordlearnersdictionaries.com/media/english/fullsize\n",
    "\n",
    "    for index, my_def in enumerate(main_defs):\n",
    "        my_dic[\"definition_\" + str(index+1)] = my_def.text\n",
    "        print(my_def.text)\n",
    "\n",
    "    for jndex, my_ex in enumerate(main_examples):\n",
    "        my_dic[\"example_set_\" + str(jndex+1)] = my_ex.text\n",
    "        print(my_ex.text)\n",
    "\n",
    "    for my_pic in potential_image_links:\n",
    "        if \"https://www.oxfordlearnersdictionaries.com/media/english/fullsize\" in my_pic[\"href\"]:\n",
    "            print(my_pic['href'])\n",
    "\n",
    "    my_words_dic[word] = my_dic\n",
    "    #print(len(main_defs))\n",
    "    #print(len(main_examples))\n",
    "    #print(len(potential_image_links))\n",
    "    print(my_li)\n",
    "\n",
    "for k, v in my_words_dic.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "\n",
    "#with open('ref_seshat.csv', 'w') as my_file:\n",
    "#    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "\n",
    "\n",
    "source_url = 'https://www.oxfordlearnersdictionaries.com/definition/english/'\n",
    "\n",
    "# cool trick\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "\n",
    "my_list = [\"wanderlust\", \"cushion\", \"wanderer\"]\n",
    "my_words_list_of_dics = []\n",
    "#source = requests.get(source_url, headers=headers).text\n",
    "for word in my_list:\n",
    "    my_dic_for_this_word = {\n",
    "        \"word\": word,\n",
    "        \"pos\": \"xyz\",\n",
    "        \"phon\": \"abc\",\n",
    "    }\n",
    "    for i in [1,2,3,4]:\n",
    "        my_word_url = source_url + word + \"_\" + str(i)\n",
    "        source = requests.get(my_word_url, headers=headers)\n",
    "        soup = BeautifulSoup(source.content.decode('utf-8'), 'lxml')\n",
    "        main_defs = soup.find_all('span', class_ = 'def')\n",
    "        \n",
    "        if not main_defs:\n",
    "            continue\n",
    "        \n",
    "        # parts of speech\n",
    "        try:\n",
    "            my_pos = soup.find('span', class_ = 'pos')\n",
    "            my_dic_for_this_word[\"pos\"] = my_pos.text\n",
    "        except:\n",
    "            my_dic_for_this_word[\"pos\"] = \"NoPOSFound\"\n",
    "\n",
    "        # phonetics\n",
    "        try:\n",
    "            my_american_pros = soup.find('div', class_=\"phons_n_am\")\n",
    "            my_american_pro = my_american_pros.find_all('span', class_ = 'phon')\n",
    "            my_dic_for_this_word[\"phon\"] = my_american_pro[0].text\n",
    "        except:\n",
    "            my_dic_for_this_word[\"phon\"] = \"NoProFound\"\n",
    "            \n",
    "        # ol with a class of sense_single or senses_multiple\n",
    "        try:\n",
    "            my_multiple_defs = soup.find('ol', class_=\"senses_multiple\")\n",
    "            # number of defs\n",
    "            main_defs = my_multiple_defs.find('span', class_ = 'def')\n",
    "            for index, my_def in enumerate(main_defs):\n",
    "                list_item_id = word + \"_sng_\" + str(index+1)\n",
    "                my_smaller_soup = my_def.find(id=list_item_id)\n",
    "                my_dic_for_this_word[\"def_\" + str(index+1)] = my_def.text\n",
    "                try:\n",
    "                    my_examples = my_smaller_soup.find_all('span', class_ = 'x')\n",
    "                    my_dic[\"example_set_\" + str(index+1)] = [my_ex.text for my_ex in my_examples]\n",
    "                except:\n",
    "                    my_dic[\"example_set_\" + str(index+1)] = \"NoExamples\"              \n",
    "        except:\n",
    "            my_single_def = soup.find('ol', class_=\"sense_single\")\n",
    "            list_item_id = word + \"_sng_1\"\n",
    "            my_smaller_soup = my_single_def.find(id=list_item_id)\n",
    "            # the only def:\n",
    "            main_def = my_smaller_soup.find('span', class_ = 'def')\n",
    "            my_dic_for_this_word[\"def_1\"] = main_def.text\n",
    "            # the only set of examples:\n",
    "            try:\n",
    "                main_examples = my_smaller_soup.find_all('span', class_ = 'x')\n",
    "                my_dic[\"example_set_1\"] = [my_ex.text for my_ex in main_examples]\n",
    "            except:\n",
    "                my_dic[\"example_set_1\"] = \"NoExamples\"\n",
    "        my_words_list_of_dics.append(my_dic_for_this_word)\n",
    "        \n",
    "\n",
    "\n",
    "        main_examples = my_smaller_soup.find_all('span', class_ = 'x')\n",
    "        \n",
    "        \n",
    "        # images\n",
    "        potential_image_links = soup.find_all('a', href=True)\n",
    "        #potential_image_links = soup.find_all('img')\n",
    "\n",
    "        for jndex, my_ex in enumerate(main_examples):\n",
    "            my_dic[\"example_set_\" + str(jndex+1)] = my_ex.text\n",
    "            print(my_ex.text)\n",
    "        print(my_american_pro[0].text)\n",
    "\n",
    "\n",
    "#with open('ref_seshat.csv', 'w') as my_file:\n",
    "#    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cushion_topg_3 > div > span.phonetics > div.phons_n_am > span\n",
    "#wanderer_topg_1 > div > span.phonetics > div.phons_n_am > span\n",
    "#wanderlust_topg_1 > div > span.phonetics > div.phons_n_am > span\n",
    "#take_topg_2 > div > span.phonetics > div.phons_br > span\n",
    "#take_topg_2 > div > span.phonetics > div.phons_n_am > span\n",
    "\n",
    "#take_topg_57 > div > span.phonetics > div.phons_n_am > span\n",
    "\n",
    "#wanderlust_topg_1 > div > span.phonetics > div.phons_n_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-roller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pet does not work properly because pet_sng_4 is the first id ... Weird\n",
    "\n",
    "my_words_list_of_dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_converter = {\n",
    "    \"noun\": \"n\",\n",
    "    \"verb\": \"v\",\n",
    "    \"adjective\": \"adj\",\n",
    "    \"adverb\": \"adv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pos_converter.get(\"tr\", \"noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \" abc def fdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.lstrip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
