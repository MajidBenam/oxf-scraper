{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquired-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "milad_words_list = longman_to_list(\"milad/milad.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "milad_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-asthma",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "milads_list = [milad[0] for milad in milad_words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "milads_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "milads_main_dic = test_func_smaller_soup(milads_list, \"milads_jsonfile.json\")\n",
    "# get the end time\n",
    "et = time.time()\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pointed-scholar",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cushion 1\n",
      "EX_0 :  matching curtains and cushions\n",
      "EX_1 :  a floor cushion (= a large cushion that you put on the floor to sit on)\n",
      "EX_2 :  a cushion of moss on a rock\n",
      "EX_3 :  I rested my elbow on a cushion.\n",
      "EX_4 :  She plumped up the sofa cushions before the guests arrived.\n",
      "DEF_0 :  a cloth bag filled with soft material or feathers that is used, for example, to make a seat more comfortable\n",
      "EX_0 :  A hovercraft rides on a cushion of air.\n",
      "EX_1 :  Underlay forms a cushion between the carpet and the floor, to minimize wear.\n",
      "DEF_1 :  a layer of something between two surfaces that keeps them apart\n",
      "EX_0 :  His savings were a comfortable cushion against financial problems.\n",
      "EX_1 :  The team built up a safe cushion of two goals in the first half.\n",
      "DEF_2 :  (cushion (against something)) something that protects you against something unpleasant that might happen\n",
      "EX_1 :  NO_EXAMPLES\n",
      "DEF_3 :  the soft inside edge along each side of the table that the balls bounce off\n",
      "cushion 2\n",
      "EX_0 :  My fall was cushioned by the deep snow.\n",
      "DEF_0 :  (cushion something) to make the effect of a fall or hit less severe\n",
      "EX_0 :  The south of the country has been cushioned from the worst effects of the recession.\n",
      "EX_1 :  He broke the news of my brother's death to me, making no effort to cushion the blow (= make the news less shocking).\n",
      "EX_2 :  Homeowners will be cushioned from any tax rises.\n",
      "DEF_1 :  (cushion somebody/something (against/from something)) to protect somebody/something from being hurt or damaged or from the unpleasant effects of something\n",
      "cushion 3\n",
      "defiance 1\n",
      "EX_0 :  a look/an act/a gesture of defiance\n",
      "EX_1 :  (in defiance of something) Nuclear testing was resumed in defiance of an international ban.\n",
      "DEF_0 :  the act of openly refusing to obey somebody/something\n",
      "defiance 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cushion': {1: {0: {'EX_0': 'matching curtains and cushions',\n",
       "    'EX_1': 'a floor cushion (= a large cushion that you put on the floor to sit on)',\n",
       "    'EX_2': 'a cushion of moss on a rock',\n",
       "    'EX_3': 'I rested my elbow on a cushion.',\n",
       "    'EX_4': 'She plumped up the sofa cushions before the guests arrived.',\n",
       "    'DEF_0': 'a cloth bag filled with soft material or feathers that is used, for example, to make a seat more comfortable',\n",
       "    'PHON': '/ˈkʊʃn/',\n",
       "    'POS': 'noun'},\n",
       "   1: {'EX_0': 'A hovercraft rides on a cushion of air.',\n",
       "    'EX_1': 'Underlay forms a cushion between the carpet and the floor, to minimize wear.',\n",
       "    'DEF_1': 'a layer of something between two surfaces that keeps them apart',\n",
       "    'PHON': '/ˈkʊʃn/',\n",
       "    'POS': 'noun'},\n",
       "   2: {'EX_0': 'His savings were a comfortable cushion against financial problems.',\n",
       "    'EX_1': 'The team built up a safe cushion of two goals in the first half.',\n",
       "    'DEF_2': '(cushion (against something)) something that protects you against something unpleasant that might happen',\n",
       "    'PHON': '/ˈkʊʃn/',\n",
       "    'POS': 'noun'},\n",
       "   3: {'EX_1': 'NO_EXAMPLES',\n",
       "    'DEF_3': 'the soft inside edge along each side of the table that the balls bounce off',\n",
       "    'PHON': '/ˈkʊʃn/',\n",
       "    'POS': 'noun'}},\n",
       "  2: {0: {'EX_0': 'My fall was cushioned by the deep snow.',\n",
       "    'DEF_0': '(cushion something) to make the effect of a fall or hit less severe',\n",
       "    'PHON': '/ˈkʊʃn/',\n",
       "    'POS': 'verb'},\n",
       "   1: {'EX_0': 'The south of the country has been cushioned from the worst effects of the recession.',\n",
       "    'EX_1': \"He broke the news of my brother's death to me, making no effort to cushion the blow (= make the news less shocking).\",\n",
       "    'EX_2': 'Homeowners will be cushioned from any tax rises.',\n",
       "    'DEF_1': '(cushion somebody/something (against/from something)) to protect somebody/something from being hurt or damaged or from the unpleasant effects of something',\n",
       "    'PHON': '/ˈkʊʃn/',\n",
       "    'POS': 'verb'}}},\n",
       " 'defiance': {1: {0: {'EX_0': 'a look/an act/a gesture of defiance',\n",
       "    'EX_1': '(in defiance of something) Nuclear testing was resumed in defiance of an international ban.',\n",
       "    'DEF_0': 'the act of openly refusing to obey somebody/something',\n",
       "    'PHON': '/dɪˈfaɪəns/',\n",
       "    'POS': 'noun'}}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_func_smaller_soup([\"cushion\",\"defiance\"], \"majid_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "my_main_dic = test_func_smaller_soup(my_list)\n",
    "# get the end time\n",
    "et = time.time()\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(my_main_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "with open('my_json_file_of_oxford_test_dic.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in my_sngs:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dic = test_func(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(my_dic[\"wise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-attack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-sport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"maroon\"\n",
    "word_dic = {}\n",
    "entry_dic = {}\n",
    "for index, item in enumerate(my_main_defs):\n",
    "    inner_dic = {}\n",
    "    for i in range(len(item)):\n",
    "        a_def = item[i].text\n",
    "        good_key_for_def = \"DEF_\" + str(i+1)\n",
    "        inner_dic[good_key_for_def] = a_def\n",
    "        print(a_def)\n",
    "    entry_dic[index] = inner_dic\n",
    "word_dic[word] = entry_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-contractor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-idaho",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-degree",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-carry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-point",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-overall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "\n",
    "\n",
    "source_url = 'https://www.oxfordlearnersdictionaries.com/definition/english/'\n",
    "\n",
    "# cool trick\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "\n",
    "my_list = [\"cushion\", \"trivial\", \"wanderer\"]\n",
    "my_words_dic = {}\n",
    "#source = requests.get(source_url, headers=headers).text\n",
    "for word in my_list:\n",
    "    my_dic = {}\n",
    "    try:\n",
    "        my_word_url = source_url + word\n",
    "        source = requests.get(my_word_url, headers=headers)\n",
    "        soup = BeautifulSoup(source.content.decode('utf-8'), 'lxml')\n",
    "        main_defs = soup.find_all('span', class_ = 'def')\n",
    "    except:\n",
    "        print(\"Bad Word...\")\n",
    "        \n",
    "    my_li = soup.find(id=\"cushion_sng_1\")\n",
    "    # selects the main text\n",
    "\n",
    "    main_examples = soup.find_all('span', class_ = 'x')\n",
    "    potential_image_links = soup.find_all('a', href=True)\n",
    "    #potential_image_links = soup.find_all('img')\n",
    "\n",
    "    # https://www.oxfordlearnersdictionaries.com/media/english/fullsize\n",
    "\n",
    "    for index, my_def in enumerate(main_defs):\n",
    "        my_dic[\"definition_\" + str(index+1)] = my_def.text\n",
    "        print(my_def.text)\n",
    "\n",
    "    for jndex, my_ex in enumerate(main_examples):\n",
    "        my_dic[\"example_set_\" + str(jndex+1)] = my_ex.text\n",
    "        print(my_ex.text)\n",
    "\n",
    "    for my_pic in potential_image_links:\n",
    "        if \"https://www.oxfordlearnersdictionaries.com/media/english/fullsize\" in my_pic[\"href\"]:\n",
    "            print(my_pic['href'])\n",
    "\n",
    "    my_words_dic[word] = my_dic\n",
    "    #print(len(main_defs))\n",
    "    #print(len(main_examples))\n",
    "    #print(len(potential_image_links))\n",
    "    print(my_li)\n",
    "\n",
    "for k, v in my_words_dic.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "\n",
    "#with open('ref_seshat.csv', 'w') as my_file:\n",
    "#    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "\n",
    "\n",
    "source_url = 'https://www.oxfordlearnersdictionaries.com/definition/english/'\n",
    "\n",
    "# cool trick\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "\n",
    "my_list = [\"wanderlust\", \"cushion\", \"wanderer\"]\n",
    "my_words_list_of_dics = []\n",
    "#source = requests.get(source_url, headers=headers).text\n",
    "for word in my_list:\n",
    "    my_dic_for_this_word = {\n",
    "        \"word\": word,\n",
    "        \"pos\": \"xyz\",\n",
    "        \"phon\": \"abc\",\n",
    "    }\n",
    "    for i in [1,2,3,4]:\n",
    "        my_word_url = source_url + word + \"_\" + str(i)\n",
    "        source = requests.get(my_word_url, headers=headers)\n",
    "        soup = BeautifulSoup(source.content.decode('utf-8'), 'lxml')\n",
    "        main_defs = soup.find_all('span', class_ = 'def')\n",
    "        \n",
    "        if not main_defs:\n",
    "            continue\n",
    "        \n",
    "        # parts of speech\n",
    "        try:\n",
    "            my_pos = soup.find('span', class_ = 'pos')\n",
    "            my_dic_for_this_word[\"pos\"] = my_pos.text\n",
    "        except:\n",
    "            my_dic_for_this_word[\"pos\"] = \"NoPOSFound\"\n",
    "\n",
    "        # phonetics\n",
    "        try:\n",
    "            my_american_pros = soup.find('div', class_=\"phons_n_am\")\n",
    "            my_american_pro = my_american_pros.find_all('span', class_ = 'phon')\n",
    "            my_dic_for_this_word[\"phon\"] = my_american_pro[0].text\n",
    "        except:\n",
    "            my_dic_for_this_word[\"phon\"] = \"NoProFound\"\n",
    "            \n",
    "        # ol with a class of sense_single or senses_multiple\n",
    "        try:\n",
    "            my_multiple_defs = soup.find('ol', class_=\"senses_multiple\")\n",
    "            # number of defs\n",
    "            main_defs = my_multiple_defs.find('span', class_ = 'def')\n",
    "            for index, my_def in enumerate(main_defs):\n",
    "                list_item_id = word + \"_sng_\" + str(index+1)\n",
    "                my_smaller_soup = my_def.find(id=list_item_id)\n",
    "                my_dic_for_this_word[\"def_\" + str(index+1)] = my_def.text\n",
    "                try:\n",
    "                    my_examples = my_smaller_soup.find_all('span', class_ = 'x')\n",
    "                    my_dic[\"example_set_\" + str(index+1)] = [my_ex.text for my_ex in my_examples]\n",
    "                except:\n",
    "                    my_dic[\"example_set_\" + str(index+1)] = \"NoExamples\"              \n",
    "        except:\n",
    "            my_single_def = soup.find('ol', class_=\"sense_single\")\n",
    "            list_item_id = word + \"_sng_1\"\n",
    "            my_smaller_soup = my_single_def.find(id=list_item_id)\n",
    "            # the only def:\n",
    "            main_def = my_smaller_soup.find('span', class_ = 'def')\n",
    "            my_dic_for_this_word[\"def_1\"] = main_def.text\n",
    "            # the only set of examples:\n",
    "            try:\n",
    "                main_examples = my_smaller_soup.find_all('span', class_ = 'x')\n",
    "                my_dic[\"example_set_1\"] = [my_ex.text for my_ex in main_examples]\n",
    "            except:\n",
    "                my_dic[\"example_set_1\"] = \"NoExamples\"\n",
    "        my_words_list_of_dics.append(my_dic_for_this_word)\n",
    "        \n",
    "\n",
    "\n",
    "        main_examples = my_smaller_soup.find_all('span', class_ = 'x')\n",
    "        \n",
    "        \n",
    "        # images\n",
    "        potential_image_links = soup.find_all('a', href=True)\n",
    "        #potential_image_links = soup.find_all('img')\n",
    "\n",
    "        for jndex, my_ex in enumerate(main_examples):\n",
    "            my_dic[\"example_set_\" + str(jndex+1)] = my_ex.text\n",
    "            print(my_ex.text)\n",
    "        print(my_american_pro[0].text)\n",
    "\n",
    "\n",
    "#with open('ref_seshat.csv', 'w') as my_file:\n",
    "#    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cushion_topg_3 > div > span.phonetics > div.phons_n_am > span\n",
    "#wanderer_topg_1 > div > span.phonetics > div.phons_n_am > span\n",
    "#wanderlust_topg_1 > div > span.phonetics > div.phons_n_am > span\n",
    "#take_topg_2 > div > span.phonetics > div.phons_br > span\n",
    "#take_topg_2 > div > span.phonetics > div.phons_n_am > span\n",
    "\n",
    "#take_topg_57 > div > span.phonetics > div.phons_n_am > span\n",
    "\n",
    "#wanderlust_topg_1 > div > span.phonetics > div.phons_n_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-roller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pet does not work properly because pet_sng_4 is the first id ... Weird\n",
    "\n",
    "my_words_list_of_dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_converter = {\n",
    "    \"noun\": \"n\",\n",
    "    \"verb\": \"v\",\n",
    "    \"adjective\": \"adj\",\n",
    "    \"adverb\": \"adv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pos_converter.get(\"tr\", \"noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \" abc def fdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.lstrip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
